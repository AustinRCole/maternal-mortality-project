{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.17.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\austi\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>state_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>deaths</th>\n",
       "      <th>births</th>\n",
       "      <th>maternal_mortality_ratio</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>prem_death_val</th>\n",
       "      <th>smoking_val</th>\n",
       "      <th>uninsured_val</th>\n",
       "      <th>all_determs_val</th>\n",
       "      <th>all_outcomes_val</th>\n",
       "      <th>chlamydia_val</th>\n",
       "      <th>prem_death_ri_val</th>\n",
       "      <th>teen_birth_val</th>\n",
       "      <th>primary_care_val</th>\n",
       "      <th>low_birthweight_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US.AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59657.0</td>\n",
       "      <td>20.11</td>\n",
       "      <td>2505795.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10095.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>103.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US.AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>35.0</td>\n",
       "      <td>59151.0</td>\n",
       "      <td>59.17</td>\n",
       "      <td>2507714.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10097.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>600.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>116.4</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US.AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>41.0</td>\n",
       "      <td>58941.0</td>\n",
       "      <td>69.56</td>\n",
       "      <td>2514911.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10321.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>543.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>30.1</td>\n",
       "      <td>119.3</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US.AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>31.0</td>\n",
       "      <td>57761.0</td>\n",
       "      <td>53.67</td>\n",
       "      <td>2523756.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>553.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>28.4</td>\n",
       "      <td>122.8</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US.AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58615.0</td>\n",
       "      <td>59.71</td>\n",
       "      <td>2533668.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10435.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>614.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2014</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US.WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>43.784440</td>\n",
       "      <td>-88.787868</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67161.0</td>\n",
       "      <td>23.82</td>\n",
       "      <td>2898057.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6207.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.067</td>\n",
       "      <td>415.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>125.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US.WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>43.784440</td>\n",
       "      <td>-88.787868</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67041.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>2903737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6365.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.046</td>\n",
       "      <td>411.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>125.3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2016</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US.WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>43.784440</td>\n",
       "      <td>-88.787868</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66615.0</td>\n",
       "      <td>22.52</td>\n",
       "      <td>2905282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6324.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.106</td>\n",
       "      <td>403.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2017</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US.WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>43.784440</td>\n",
       "      <td>-88.787868</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64975.0</td>\n",
       "      <td>18.47</td>\n",
       "      <td>2912745.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6437.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.072</td>\n",
       "      <td>423.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>145.2</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2019</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US.WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>43.784440</td>\n",
       "      <td>-88.787868</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63270.0</td>\n",
       "      <td>20.55</td>\n",
       "      <td>2925225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.074</td>\n",
       "      <td>478.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>152.4</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year      state     id state_code   latitude  longitude  deaths   births  \\\n",
       "0    2015    Alabama  US.AL         AL  32.318231 -86.902298    12.0  59657.0   \n",
       "1    2016    Alabama  US.AL         AL  32.318231 -86.902298    35.0  59151.0   \n",
       "2    2017    Alabama  US.AL         AL  32.318231 -86.902298    41.0  58941.0   \n",
       "3    2018    Alabama  US.AL         AL  32.318231 -86.902298    31.0  57761.0   \n",
       "4    2019    Alabama  US.AL         AL  32.318231 -86.902298    35.0  58615.0   \n",
       "..    ...        ...    ...        ...        ...        ...     ...      ...   \n",
       "303  2014  Wisconsin  US.WI         WI  43.784440 -88.787868    16.0  67161.0   \n",
       "304  2015  Wisconsin  US.WI         WI  43.784440 -88.787868    11.0  67041.0   \n",
       "305  2016  Wisconsin  US.WI         WI  43.784440 -88.787868    15.0  66615.0   \n",
       "306  2017  Wisconsin  US.WI         WI  43.784440 -88.787868    12.0  64975.0   \n",
       "307  2019  Wisconsin  US.WI         WI  43.784440 -88.787868    13.0  63270.0   \n",
       "\n",
       "     maternal_mortality_ratio  population  ...  prem_death_val  smoking_val  \\\n",
       "0                       20.11   2505795.0  ...         10095.0         21.1   \n",
       "1                       59.17   2507714.0  ...         10097.0         21.4   \n",
       "2                       69.56   2514911.0  ...         10321.0         21.5   \n",
       "3                       53.67   2523756.0  ...         10720.0         20.9   \n",
       "4                       59.71   2533668.0  ...         10435.0         19.2   \n",
       "..                        ...         ...  ...             ...          ...   \n",
       "303                     23.82   2898057.0  ...          6207.0         18.7   \n",
       "304                     16.41   2903737.0  ...          6365.0         17.4   \n",
       "305                     22.52   2905282.0  ...          6324.0         17.3   \n",
       "306                     18.47   2912745.0  ...          6437.0         17.1   \n",
       "307                     20.55   2925225.0  ...          6800.0         16.4   \n",
       "\n",
       "     uninsured_val  all_determs_val  all_outcomes_val  chlamydia_val  \\\n",
       "0             12.9           -0.371            -0.325          611.0   \n",
       "1             11.1           -0.427            -0.366          600.2   \n",
       "2              9.6           -0.427            -0.335          543.6   \n",
       "3              9.3           -0.483            -0.356          553.6   \n",
       "4              9.7           -0.437            -0.383          614.1   \n",
       "..             ...              ...               ...            ...   \n",
       "303            9.0            0.165             0.067          415.4   \n",
       "304            8.2            0.146             0.046          411.6   \n",
       "305            6.5            0.114             0.106          403.2   \n",
       "306            5.5            0.201             0.072          423.5   \n",
       "307            5.5            0.129             0.074          478.6   \n",
       "\n",
       "     prem_death_ri_val  teen_birth_val  primary_care_val  low_birthweight_val  \n",
       "0                  1.2            34.3             103.5                 10.0  \n",
       "1                  1.1            32.0             116.4                 10.1  \n",
       "2                  1.2            30.1             119.3                 10.4  \n",
       "3                  1.1            28.4             122.8                 10.3  \n",
       "4                  1.2            27.0             122.8                 10.3  \n",
       "..                 ...             ...               ...                  ...  \n",
       "303                2.0            21.9             125.0                  7.1  \n",
       "304                1.9            19.6             125.3                  7.0  \n",
       "305                1.9            18.0             140.3                  7.3  \n",
       "306                1.9            16.2             145.2                  7.3  \n",
       "307                2.0            13.8             152.4                  7.7  \n",
       "\n",
       "[308 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_values_raw = pd.read_csv(\"../../ETL/output_file/state_X_values_proj3.csv\")\n",
    "\n",
    "#X_values_raw\n",
    "\n",
    "df = pd.read_csv(\"../Resources/non_race_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.5, 211.6, 330.1, ...,  34.3, 103.5,  10. ],\n",
       "       [  9.1, 211.1, 332.9, ...,  32. , 116.4,  10.1],\n",
       "       [  8.9, 210.6, 339.6, ...,  30.1, 119.3,  10.4],\n",
       "       ...,\n",
       "       [  7.9, 191.6, 236.8, ...,  18. , 140.3,   7.3],\n",
       "       [  7.4, 191.7, 238.1, ...,  16.2, 145.2,   7.3],\n",
       "       [  6.8, 190.4, 242.6, ...,  13.8, 152.4,   7.7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"year\", \"state\", \"id\", \"state_code\", \"latitude\", \"longitude\", \"deaths\", \"births\", \"maternal_mortality_ratio\", \"population\", \"employer\", \"non_group\", \"medicaid\", \"medicare\", \"military\", \"uninsured\"]).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.11, 59.17, 69.56, 53.67, 59.71, 19.43, 17.54, 28.92, 26.87,\n",
       "       27.62, 23.43, 29.58, 29.31, 29.73, 40.31, 50.24, 33.73, 25.83,\n",
       "       46.94, 39.65, 59.72, 41.15, 44.42, 37.31, 62.13, 38.29, 20.3 ,\n",
       "       16.07, 14.14, 16.08, 15.56, 17.5 , 17.08, 18.62, 19.08, 17.81,\n",
       "       15.9 , 18.46, 24.31, 15.02, 24.02, 27.96, 23.86, 37.55, 31.23,\n",
       "       32.07, 21.9 , 23.43, 30.03, 38.53, 28.18, 30.32, 22.22, 21.46,\n",
       "       24.37, 31.36, 25.46, 28.37, 36.25, 30.7 , 63.69, 79.42, 74.58,\n",
       "       56.14, 57.26, 49.14, 50.64, 43.11, 20.45, 17.55, 27.9 , 21.99,\n",
       "       17.21, 20.18, 25.3 , 18.13, 26.11, 15.19, 14.27, 18.46, 16.68,\n",
       "       51.37, 43.26, 42.12, 45.2 , 54.74, 60.17, 48.68, 28.17, 40.81,\n",
       "       27.72, 30.45, 31.23, 31.4 , 27.06, 38.62, 28.91, 27.38, 36.73,\n",
       "       30.47, 19.87, 34.12, 30.37, 52.3 , 32.88, 53.78, 39.57, 44.7 ,\n",
       "       74.37, 62.02, 68.01, 88.64, 67.19, 36.9 , 44.11, 23.98, 35.23,\n",
       "       32.83, 27.44, 20.85, 29.76, 21.73, 17.78, 34.9 , 23.92, 31.35,\n",
       "       25.24, 19.8 , 21.7 , 28.99, 41.04, 28.95, 25.64, 31.72, 25.36,\n",
       "       23.83, 35.3 , 21.54, 29.08, 31.51, 15.57, 19.  , 21.81, 15.91,\n",
       "       14.31, 20.07, 26.24, 14.85, 16.66, 32.63, 29.97, 45.16, 38.79,\n",
       "       33.65, 36.91, 32.12, 40.54, 60.05, 22.81, 15.63, 22.33, 45.07,\n",
       "       39.84, 45.12, 43.96, 36.14, 38.34, 32.76, 22.18, 30.76, 33.54,\n",
       "       28.06, 45.33, 34.54, 55.57, 53.24, 37.82, 41.89, 43.46, 34.58,\n",
       "       36.15, 43.97, 42.08, 28.21, 27.42, 26.52, 24.07, 26.58, 25.55,\n",
       "       26.97, 27.74, 20.46, 29.17, 34.76, 16.56,  8.17,  9.14,  8.35,\n",
       "       12.6 , 28.1 , 36.41, 31.46, 29.14, 21.02, 38.74, 39.35, 28.75,\n",
       "       25.38, 28.16, 21.59, 15.77, 29.44, 26.07, 30.69, 19.98, 34.95,\n",
       "       51.33, 37.57, 38.26, 28.44, 37.47, 24.37, 26.35, 38.03, 43.81,\n",
       "       34.14, 28.49, 22.15, 26.58, 27.5 , 26.63, 23.72, 16.06, 21.05,\n",
       "       24.84, 24.6 , 22.69, 29.41, 29.04, 21.37, 29.05, 37.94, 30.85,\n",
       "       33.11, 27.99, 29.93, 41.65, 34.4 , 48.83, 42.08, 28.23, 42.08,\n",
       "       12.16, 49.77, 35.  , 29.41, 35.5 , 30.94, 48.14, 33.44, 37.29,\n",
       "       31.59, 26.16, 34.71, 41.54, 43.37, 36.77, 38.9 , 38.44, 38.48,\n",
       "       24.83, 23.57, 31.4 , 23.46, 25.6 , 20.58, 29.9 , 10.47, 17.53,\n",
       "       13.59, 14.68, 17.42, 30.01, 45.87, 39.84, 23.04, 32.84, 13.44,\n",
       "       12.71, 16.1 , 19.44, 23.1 , 22.58, 12.36, 13.26, 27.41, 24.39,\n",
       "       36.52, 54.8 , 18.35, 17.52, 22.12, 18.  , 23.82, 16.41, 22.52,\n",
       "       18.47, 20.55])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['maternal_mortality_ratio'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -1181.98 (271.06) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train_scaled, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -930.88 (348.90) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -990.78 (422.34) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -6672.04 (10590.79) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -1144.32 (457.18) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=20)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 8s 25ms/sample - loss: 940.7041\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 149us/sample - loss: 802.6391\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 140us/sample - loss: 642.6847\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 127us/sample - loss: 472.2495\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 172us/sample - loss: 304.8545\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 192us/sample - loss: 176.3106\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 143us/sample - loss: 129.9501\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 166us/sample - loss: 157.6691\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 198us/sample - loss: 161.4437\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 263us/sample - loss: 138.4812\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 208us/sample - loss: 128.1843\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 208us/sample - loss: 133.7333\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 149us/sample - loss: 137.3449\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 231us/sample - loss: 135.9086\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 208us/sample - loss: 131.9846\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 205us/sample - loss: 128.9219\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 205us/sample - loss: 130.3958\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 179us/sample - loss: 129.4570\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 185us/sample - loss: 129.5674\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 0s 227us/sample - loss: 130.2869\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 381us/sample - loss: 130.0622\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 201us/sample - loss: 129.3788\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 240us/sample - loss: 129.6592\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 205us/sample - loss: 130.3950\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 257us/sample - loss: 129.5727\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 0s 227us/sample - loss: 128.8286\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 237us/sample - loss: 129.7071\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 269us/sample - loss: 129.9556\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 279us/sample - loss: 129.4351\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 380us/sample - loss: 128.9274\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 295us/sample - loss: 129.0644\n",
      "Epoch 32/100\n",
      "308/308 [==============================] - 0s 240us/sample - loss: 129.5005\n",
      "Epoch 33/100\n",
      "308/308 [==============================] - 0s 247us/sample - loss: 129.2393\n",
      "Epoch 34/100\n",
      "308/308 [==============================] - 0s 325us/sample - loss: 129.0333\n",
      "Epoch 35/100\n",
      "308/308 [==============================] - 0s 260us/sample - loss: 129.3575\n",
      "Epoch 36/100\n",
      "308/308 [==============================] - 0s 234us/sample - loss: 128.8340\n",
      "Epoch 37/100\n",
      "308/308 [==============================] - 0s 347us/sample - loss: 129.0534\n",
      "Epoch 38/100\n",
      "308/308 [==============================] - 0s 256us/sample - loss: 129.7545\n",
      "Epoch 39/100\n",
      "308/308 [==============================] - 0s 254us/sample - loss: 131.4526\n",
      "Epoch 40/100\n",
      "308/308 [==============================] - 0s 393us/sample - loss: 132.9436\n",
      "Epoch 41/100\n",
      "308/308 [==============================] - ETA: 0s - loss: 125.337 - 0s 302us/sample - loss: 129.9774\n",
      "Epoch 42/100\n",
      "308/308 [==============================] - 0s 386us/sample - loss: 129.3214\n",
      "Epoch 43/100\n",
      "308/308 [==============================] - 0s 479us/sample - loss: 130.7444\n",
      "Epoch 44/100\n",
      "308/308 [==============================] - 0s 432us/sample - loss: 130.8566\n",
      "Epoch 45/100\n",
      "308/308 [==============================] - 0s 283us/sample - loss: 129.6348\n",
      "Epoch 46/100\n",
      "308/308 [==============================] - 0s 385us/sample - loss: 128.2531\n",
      "Epoch 47/100\n",
      "308/308 [==============================] - 0s 358us/sample - loss: 129.9477\n",
      "Epoch 48/100\n",
      "308/308 [==============================] - 0s 351us/sample - loss: 129.2151\n",
      "Epoch 49/100\n",
      "308/308 [==============================] - 0s 389us/sample - loss: 128.6890\n",
      "Epoch 50/100\n",
      "308/308 [==============================] - 0s 357us/sample - loss: 129.3117\n",
      "Epoch 51/100\n",
      "308/308 [==============================] - 0s 523us/sample - loss: 129.2289\n",
      "Epoch 52/100\n",
      "308/308 [==============================] - 0s 540us/sample - loss: 129.4698\n",
      "Epoch 53/100\n",
      "308/308 [==============================] - 0s 362us/sample - loss: 129.6031\n",
      "Epoch 54/100\n",
      "308/308 [==============================] - 0s 360us/sample - loss: 128.8121\n",
      "Epoch 55/100\n",
      "308/308 [==============================] - 0s 586us/sample - loss: 128.5574\n",
      "Epoch 56/100\n",
      "308/308 [==============================] - 0s 319us/sample - loss: 128.9929\n",
      "Epoch 57/100\n",
      "308/308 [==============================] - 0s 403us/sample - loss: 128.8552\n",
      "Epoch 58/100\n",
      "308/308 [==============================] - 0s 338us/sample - loss: 128.8356\n",
      "Epoch 59/100\n",
      "308/308 [==============================] - 0s 360us/sample - loss: 128.6207\n",
      "Epoch 60/100\n",
      "308/308 [==============================] - 0s 562us/sample - loss: 128.6072\n",
      "Epoch 61/100\n",
      "308/308 [==============================] - 0s 356us/sample - loss: 128.7166\n",
      "Epoch 62/100\n",
      "308/308 [==============================] - 0s 250us/sample - loss: 128.7328\n",
      "Epoch 63/100\n",
      "308/308 [==============================] - 0s 231us/sample - loss: 128.8004\n",
      "Epoch 64/100\n",
      "308/308 [==============================] - 0s 334us/sample - loss: 129.3552\n",
      "Epoch 65/100\n",
      "308/308 [==============================] - 0s 266us/sample - loss: 129.0692\n",
      "Epoch 66/100\n",
      "308/308 [==============================] - 0s 208us/sample - loss: 128.5585\n",
      "Epoch 67/100\n",
      "308/308 [==============================] - 0s 265us/sample - loss: 128.6090\n",
      "Epoch 68/100\n",
      "308/308 [==============================] - 0s 281us/sample - loss: 128.6715\n",
      "Epoch 69/100\n",
      "308/308 [==============================] - 0s 398us/sample - loss: 128.5810\n",
      "Epoch 70/100\n",
      "308/308 [==============================] - 0s 442us/sample - loss: 128.1324\n",
      "Epoch 71/100\n",
      "308/308 [==============================] - 0s 620us/sample - loss: 128.9874\n",
      "Epoch 72/100\n",
      "308/308 [==============================] - 0s 526us/sample - loss: 128.8754\n",
      "Epoch 73/100\n",
      "308/308 [==============================] - 0s 458us/sample - loss: 128.2928\n",
      "Epoch 74/100\n",
      "308/308 [==============================] - 0s 451us/sample - loss: 128.7700\n",
      "Epoch 75/100\n",
      "308/308 [==============================] - 0s 669us/sample - loss: 128.5442\n",
      "Epoch 76/100\n",
      "308/308 [==============================] - ETA: 0s - loss: 129.887 - 0s 409us/sample - loss: 129.0265\n",
      "Epoch 77/100\n",
      "308/308 [==============================] - 0s 702us/sample - loss: 128.6810\n",
      "Epoch 78/100\n",
      "308/308 [==============================] - 0s 463us/sample - loss: 128.3253\n",
      "Epoch 79/100\n",
      "308/308 [==============================] - 0s 519us/sample - loss: 128.9546\n",
      "Epoch 80/100\n",
      "308/308 [==============================] - 0s 518us/sample - loss: 129.4942\n",
      "Epoch 81/100\n",
      "308/308 [==============================] - 0s 500us/sample - loss: 129.8870\n",
      "Epoch 82/100\n",
      "308/308 [==============================] - 0s 497us/sample - loss: 128.5405s - loss: 127.408\n",
      "Epoch 83/100\n",
      "308/308 [==============================] - 0s 386us/sample - loss: 129.5226\n",
      "Epoch 84/100\n",
      "308/308 [==============================] - 0s 399us/sample - loss: 133.2647\n",
      "Epoch 85/100\n",
      "308/308 [==============================] - 0s 377us/sample - loss: 132.1496\n",
      "Epoch 86/100\n",
      "308/308 [==============================] - 0s 620us/sample - loss: 129.7614\n",
      "Epoch 87/100\n",
      "308/308 [==============================] - 0s 617us/sample - loss: 128.1398\n",
      "Epoch 88/100\n",
      "308/308 [==============================] - 0s 480us/sample - loss: 128.1438\n",
      "Epoch 89/100\n",
      "308/308 [==============================] - 0s 383us/sample - loss: 129.3478\n",
      "Epoch 90/100\n",
      "308/308 [==============================] - 0s 325us/sample - loss: 131.1317\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 360us/sample - loss: 131.3993\n",
      "Epoch 92/100\n",
      "308/308 [==============================] - 0s 321us/sample - loss: 129.3622\n",
      "Epoch 93/100\n",
      "308/308 [==============================] - 0s 358us/sample - loss: 128.9123\n",
      "Epoch 94/100\n",
      "308/308 [==============================] - 0s 340us/sample - loss: 129.9427\n",
      "Epoch 95/100\n",
      "308/308 [==============================] - 0s 240us/sample - loss: 129.1049\n",
      "Epoch 96/100\n",
      "308/308 [==============================] - ETA: 0s - loss: 118.270 - 0s 273us/sample - loss: 128.8492\n",
      "Epoch 97/100\n",
      "308/308 [==============================] - 0s 253us/sample - loss: 128.5066\n",
      "Epoch 98/100\n",
      "308/308 [==============================] - 0s 276us/sample - loss: 128.4659\n",
      "Epoch 99/100\n",
      "308/308 [==============================] - ETA: 0s - loss: 137.867 - 0s 266us/sample - loss: 128.7050\n",
      "Epoch 100/100\n",
      "308/308 [==============================] - 0s 240us/sample - loss: 128.4267\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-80dd8b6c843b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mann_visualizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mann_viz\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mann_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"My first neural network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ann_visualizer\\visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[1;34m(model, view, filename, title)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \"\"\"\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=26, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X,y,nb_epoch=100, batch_size=100)\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model, title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
